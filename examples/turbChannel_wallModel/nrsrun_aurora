#!/bin/bash
set -e

#--------------------------------------
: ${QUEUE:="lustre_scaling"}
: ${NEKRS_GPU_MPI:=0}
: ${NEKRS_BACKEND:="dpcpp"}
: ${RANKS_PER_NODE:=2}
: ${CPU_BIND_LIST:="1:8:16:24:32:40:53:60:68:76:84:92"}
: ${OCCA_DPCPP_COMPILER_FLAGS:="-O3 -fsycl -fsycl-targets=intel_gpu_pvc -ftarget-register-alloc-mode=pvc:auto -fma"}
: ${ONEAPI_SDK:=""}
: ${FRAMEWORKS_MODULE:="frameworks"}
#--------------------------------------

source $NEKRS_HOME/bin/nrsqsub_utils
setup $# 1

TOTAL_RANKS=$(( nodes * RANKS_PER_NODE ))
chk_case $TOTAL_RANKS

#--------------------------------------
# Generate the run script
RFILE=run.sh
echo "#!/bin/bash" > $RFILE

echo -e "\nexport TZ='/usr/share/zoneinfo/US/Central'" >> $RFILE

echo -e "\necho Jobid: \$PBS_JOBID" >>$RFILE
echo "echo Running on host \`hostname\`" >>$RFILE
echo "echo Running on nodes \`cat \$PBS_NODEFILE\`" >>$RFILE

echo "module restore" >> $RFILE
echo "module load ${FRAMEWORKS_MODULE}" >> $RFILE
echo "module list" >> $RFILE

echo -e "\nexport NEKRS_HOME=$NEKRS_HOME" >>$RFILE

echo "export OCCA_DPCPP_COMPILER_FLAGS=\"$OCCA_DPCPP_COMPILER_FLAGS\"" >> $RFILE

# Cray MPI libfabric defaults
echo "export FI_CXI_RX_MATCH_MODE=hybrid" >> $RFILE # required by parRSB

# Temporary workaround while waiting on bugfix in runtime
echo "export UR_L0_USE_COPY_ENGINE=0" >> $RFILE

echo -e "\n# Run nekRS" >>$RFILE
echo "mpiexec -n ${TOTAL_RANKS} -ppn ${RANKS_PER_NODE} --cpu-bind=list:${CPU_BIND_LIST} -- $NEKRS_HOME/bin/nekrs --setup ${case} --backend ${NEKRS_BACKEND}" >> $RFILE

echo -e "\n# Post-process" >>$RFILE
echo "awk '/^#/ {line=NR} END{print line}' NekAvgData_1D.csv | { read lh; awk -v lh=\"\$lh\" 'NR==1 || NR==lh || NR>lh' NekAvgData_1D.csv; } > postprocess_data.csv" >> $RFILE
echo "python plot_channel_data.py postprocess_data.csv 950 0" >>$RFILE
chmod u+x $RFILE

